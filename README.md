# NotYet.News


NotYet.News is a satirical online publication with news stories generated by AI based on today's top news.

## Build Journal

### Current

Setting up backend cron job with

```
pnpm run cron
```

Connects to NYT API, need to connect to Open AI API

Remember to use `pnpm` for installing packages.


### TODO

1. CRON Job
2. Link to previous dates
3. Link to articles
4. Theme Switcher
5. Footer


### Initial Build

Started by talking to my brother about the project idea a little bit. He came up with the name, which I instantly liked.

Bootstrapped with Vercel's AI SDK.

Played around with Chat GPT prompts to see what kind of results I could get - see https://chat.openai.com/share/87bd0bb4-c5dd-46bd-a805-a0c6b47fdbd1

Signed up for the NYTimes API to get content for the prompts.

Set up a serverless edge function to:

1. Get articles from the NYTimes API
2. For each article, send a prompt to gpt-4 `Generate a news article in the style of The Onion set 100 years into the future on this article from today's news. Factor in how drastically different the world would be in 100 years. This news article might not even be relevant: ${article}`
3. Use an OpenAI Function to coerce the model to always return structured JSON as suggested by @jaredpalmer https://twitter.com/jaredpalmer/status/1673056725446844417
4. Ask Chat GPT to also generate a prompt for an article image from DALLE 
5. After the image is created, transfer it from the temporary DALLE url to S3.
6. When all the parody articles are generated, stringify the JSON and upload to S3 with the date as the filename.

Next I created a Next.js page that would load the JSON from S3 and render a layout with a grid layout.


### CRON Job

I had the script generation running locally, where it could build a JSON file with all the articles and images. However, this process takes a long time, about 15 minutes or so. Vercel has a 10 second limit on their serverless functions. 

Rewrote it to run locally as a node script. Looked into services that I could use to run the script as a cron job and settled on [Render](https://render.com/).

So now the cron script runs once a day to generate the content and upload the JSON as a file to S3. My frontend on Next.js loads the JSON from S3 and generates the front page and article pages.









